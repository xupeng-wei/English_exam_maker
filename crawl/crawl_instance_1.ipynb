{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import re\n",
    "import chardet\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_urls = [\"https://www.trjlseng.com/cyst/\", \"https://www.trjlseng.com/cyst/list_2.html\", \n",
    "             \"https://www.trjlseng.com/cest/\", \"https://www.trjlseng.com/cest/list_2.html\", \n",
    "             \"https://www.trjlseng.com/csst/\", \"https://www.trjlseng.com/csst/list_2.html\"]\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "def get_page_links(base_url):\n",
    "    response = requests.get(base_url, headers=HEADERS, timeout=20)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to access {base_url}\")\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    article_links = []\n",
    "\n",
    "    for link in soup.select(\"a\"):\n",
    "        href = link.get(\"href\")\n",
    "        # check if the link is of the format /cyst/digit.html\n",
    "        if href and re.match(r\"/(cyst|cest|csst)/\\d+\\.html\", href):\n",
    "            full_url = \"https://www.trjlseng.com\" + href\n",
    "            article_links.append(full_url)\n",
    "    \n",
    "    return list(set(article_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_links = {}\n",
    "for url in meta_urls:\n",
    "    page_links[url] = get_page_links(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"trjlseng_links.pkl\", \"wb\") as f:\n",
    "    pickle.dump(page_links, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"trjlseng\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resource_link(base_url):\n",
    "    response = requests.get(base_url, headers=HEADERS, timeout=20)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to access {base_url}\")\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    for link in soup.select(\"a\"):\n",
    "        href = link.get(\"href\")\n",
    "        # check if the link is of the format /file/*\n",
    "        if href and \"/file/\" in href:\n",
    "            full_url = \"https://www.trjlseng.com\" + href\n",
    "            return full_url\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_links = {}\n",
    "meta_category = [\"cyst\", \"cest\", \"csst\"]\n",
    "for category in meta_category:\n",
    "    file_links[category] = []\n",
    "\n",
    "for raw_category, links in page_links.items():\n",
    "    for cat in meta_category:\n",
    "        if cat in raw_category:\n",
    "            break\n",
    "    for link in links:\n",
    "        file_links[cat].append(get_resource_link(link))\n",
    "\n",
    "for cat, file in file_links.items():\n",
    "    file_links[cat] = list(set(file))\n",
    "    with open(f\"trjlseng/{cat}.txt\", \"w\") as f:\n",
    "        for link in file_links[cat]:\n",
    "            f.write(link + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rarfile\n",
    "\n",
    "def download_file(url, save_path):\n",
    "    \"\"\"Download a file from a given URL and save it locally.\"\"\"\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                f.write(chunk)\n",
    "        # print(f\"Downloaded: {save_path}\")\n",
    "    else:\n",
    "        raise Exception(f\"Failed to download {url}\")\n",
    "\n",
    "def extract_rar(file_path, extract_to):\n",
    "    \"\"\"Extract a .rar file to the specified directory.\"\"\"\n",
    "    try:\n",
    "        with rarfile.RarFile(file_path) as rf:\n",
    "            rf.extractall(extract_to)\n",
    "        print(f\"Extracted: {file_path} -> {extract_to}\")\n",
    "    except rarfile.RarCannotExec as e:\n",
    "        raise Exception(f\"Extraction failed: {e}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_category = [\"cyst\", \"cest\", \"csst\"]\n",
    "\n",
    "failed_links = {}\n",
    "for category in meta_category:\n",
    "    failed_links[category] = []\n",
    "    with open(f\"trjlseng/{category}.txt\", \"r\") as f:\n",
    "        links = f.readlines()\n",
    "    \n",
    "    for link in tqdm(links):\n",
    "        try:\n",
    "            link = link.strip()\n",
    "            file_name = os.path.basename(link)\n",
    "            os.makedirs(os.path.join(\"trjlseng\", category, \"raw_zips\"), exist_ok=True)\n",
    "            download_path = os.path.join(\"trjlseng\", category, \"raw_zips\", file_name)\n",
    "            print(download_path)\n",
    "            \n",
    "            download_file(link, download_path)\n",
    "            \n",
    "            extract_dir = os.path.join(\"trjlseng\", category, \"unzip\")\n",
    "            os.makedirs(extract_dir, exist_ok=True)\n",
    "            \n",
    "            extract_rar(download_path, extract_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {link}: {e}\")\n",
    "            failed_links[category].append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eecs553",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
